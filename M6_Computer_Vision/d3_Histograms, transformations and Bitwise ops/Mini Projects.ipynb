{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green screen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a method to process an image with a green screen, replace the green screen with a background image\n",
    "\n",
    "1. Adapt it to use your webcam and try it out, you might need to change the green screen to another color that you can use as your backgrouns (for example maybe white if you have a white wall behind you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:43:43.613470Z",
     "start_time": "2021-06-10T05:43:40.888983Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T06:15:05.429375Z",
     "start_time": "2021-06-10T06:14:23.328851Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    # Our operations on the frame come here\n",
    "    #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #frame = cv2.resize(frame, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA) #to resize image\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Input', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color images to black and white and back!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using a color image, load it with openCV then transform it to HSV and make it Grayscale (without transforming it to grayscale!)\n",
    "1. Convert the grayscale image back to color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T07:07:32.430152Z",
     "start_time": "2021-06-10T07:07:31.674778Z"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('img/Lenna_(test_image).png')\n",
    "lenna = image.copy()\n",
    "\n",
    "# the hue channel models the color type, Variation of the saturation goes from unsaturated to \n",
    "# represent shades of gray and fully saturated (no white component). Value channel describes\n",
    "# the brightness or the intensity of the color\n",
    "\n",
    "# cv2.split divides a multi-channel array into several single-channel arrays\n",
    "# select the V channel as your grayscale image by splitting the HSV image in 3 and taking the 3rd channel\n",
    "lenna_hsv = cv2.cvtColor(lenna, cv2.COLOR_BGR2HSV)\n",
    "h, s, v = cv2.split(lenna_hsv)\n",
    "thresh, blck_white = cv2.threshold(v, 127, 255, cv2.THRESH_BINARY)\n",
    "#thresh, blck_white = cv2.threshold(v, 127, 255, cv2.THRESH_TRUNC)\n",
    "# (127 - 255) denotes light image\n",
    "# (0 - 127) denotes dark image\n",
    "cv2.imshow(\"Black_and_White\", blck_white)\n",
    "\n",
    "k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day or night?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using all you have learned so far about computer vision, implement at least one method (or more!) to check if a certain image corresponds to a day or a night image.\n",
    "1. Use different images to check if your approach is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T06:13:12.626587Z",
     "start_time": "2021-06-10T06:13:12.574168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light\n"
     ]
    }
   ],
   "source": [
    "#function which tells if an image is day or night\n",
    "\n",
    "def img_estim(img, thrshld):\n",
    "    image = cv2.imread(img)\n",
    "    is_light = np.mean(image) > thrshld\n",
    "    return 'light' if is_light else 'dark'\n",
    "\n",
    "print(img_estim('img/day1.jpg', 127))\n",
    "# (127 - 255) denotes light image\n",
    "# (0 - 127) denotes dark image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
