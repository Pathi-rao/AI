{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "4.3 Pytorch MNIST - Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLfgh8zGap0Q"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "    <h2 align=\"center\">Deep Learning Fundamentals</h2>\n",
        "    <h2 align=\"center\" style=\"color:#01ff84\">Multiclass Classification: MNIST</h2>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVwvCN_2ap0g"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-27T10:10:28.828826Z",
          "start_time": "2021-05-27T10:10:28.727896Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPJOpWceap0j",
        "outputId": "16fd3875-d54c-4308-94cf-ce0a77dcaef0"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "print('setup complete')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setup complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VIYQD2kap0n"
      },
      "source": [
        "## Auxliary plotting function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-27T10:15:56.618301Z",
          "start_time": "2021-05-27T10:15:56.603174Z"
        },
        "id": "wKotty_lap0o"
      },
      "source": [
        "# https://discuss.pytorch.org/t/view-classify-in-module-helper/30279/6\n",
        "\n",
        "def view_classify(img, ps):\n",
        "\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpoUrJ99ap0q"
      },
      "source": [
        "# Load MNIST Dataset\n",
        "First up, we need to get our dataset. This is provided through the `torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. Don't worry too much about the details here, you'll learn more about this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-27T10:34:08.957222Z",
          "start_time": "2021-05-27T10:28:18.480507Z"
        },
        "id": "KHf7W6iSap0s"
      },
      "source": [
        "# Define a transform to normalize the data (Preprocessing)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset    = datasets.MNIST('data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset    = datasets.MNIST('data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-27T10:39:10.144997Z",
          "start_time": "2021-05-27T10:39:10.084253Z"
        },
        "id": "-du6VosXap0y"
      },
      "source": [
        "dataiter = iter(trainloader) #does this line make the images as iterable?\n",
        "#print(trainloader)\n",
        "#print(dataiter)\n",
        "images, labels = dataiter.next()\n",
        "#print(images)\n",
        "#print(labels)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqxjvBg8ap00"
      },
      "source": [
        "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. We'd use this to loop through the dataset for training, but here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size (64, 1, 28, 28). So, 64 images per batch, 1 color channel, and 28x28 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:39.407000Z",
          "start_time": "2021-05-26T22:26:39.265256Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dL_7m7Ipap02",
        "outputId": "b647c328-36c2-4392-91f9-05cb29fad98a"
      },
      "source": [
        "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r'); #squeeze removes the 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 251,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvpNeNCqap04"
      },
      "source": [
        "## Building networks with PyTorch\n",
        "\n",
        "Here I'll use PyTorch to build a simple feedfoward network to classify the MNIST images. That is, the network will receive a digit image as input and predict the digit in the image.\n",
        "\n",
        "<img src=\"assets/mlp_mnist.png\" width=600px>\n",
        "\n",
        "To build a neural network with PyTorch, you use the `torch.nn` module. The network itself is a class inheriting from `torch.nn.Module`. You define each of the operations separately, like `nn.Linear(784, 128)` for a fully connected linear layer with 784 inputs and 128 units.\n",
        "\n",
        "The class needs to include a `forward` method that implements the forward pass through the network. In this method, you pass some input tensor `x` through each of the operations you defined earlier. The `torch.nn` module also has functional equivalents for things like ReLUs in `torch.nn.functional`. This module is usually imported as `F`. Then to use a ReLU activation on some layer (which is just a tensor), you'd do `F.relu(x)`. Below are a few different commonly used activation functions.\n",
        "\n",
        "<img src=\"assets/activation.png\" width=700px>\n",
        "\n",
        "So, for this network, I'll build it with three fully connected layers, then a softmax output for predicting classes. The softmax function is similar to the sigmoid in that it squashes inputs between 0 and 1, but it's also normalized so that all the values sum to one like a proper probability distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:39.961531Z",
          "start_time": "2021-05-26T22:26:39.946776Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gqQ_5jQap07",
        "outputId": "cfd0dfd1-51a9-4220-9abc-70ccbd350714"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    \n",
        "    # Defining the layers, 32, 16, 10 units each\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 10)\n",
        "        \n",
        "    # Forward pass through the network, returns the output logits\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "model = Network()\n",
        "model"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Network(\n",
              "  (fc1): Linear(in_features=784, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=16, bias=True)\n",
              "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiWOXOArap0-"
      },
      "source": [
        "Why the input features are 784? Because the input images have size 28 pixels x 28 pixels for a total of 784 features. Since a Multilayer perceptron accepts only flatten inputs, we need to flatten a 28x28 grid into a 784 array."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KotTTzbsap1B"
      },
      "source": [
        "### Sequential API\n",
        "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:41.213448Z",
          "start_time": "2021-05-26T22:26:41.205216Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-mTba0map1C",
        "outputId": "28bf475e-0015-4688-946c-9db71e810d08"
      },
      "source": [
        "# Hyperparameters for our network\n",
        "input_size   = 784\n",
        "hidden_sizes = [4, 4]\n",
        "output_size   = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.Softmax(dim=1))\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=4, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=4, out_features=4, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=4, out_features=10, bias=True)\n",
            "  (5): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL79zT5Fap1F"
      },
      "source": [
        "You can also pass in an `OrderedDict` to name the individual layers and operations. Note that a dictionary keys must be unique, so _each operation must have a different name_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:42.300216Z",
          "start_time": "2021-05-26T22:26:42.289009Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMUvOiKnap1G",
        "outputId": "e5e913ad-abc0-430a-a13f-13452ec2c830"
      },
      "source": [
        "model = nn.Sequential(OrderedDict([\n",
        "          ('fc1',   nn.Linear(input_size, hidden_sizes[0])),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2',   nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('output', nn.Linear(hidden_sizes[1], output_size)),\n",
        "          ('softmax', nn.Softmax(dim=1))]))\n",
        "model"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GCR2Ytdap1H"
      },
      "source": [
        "### Initializing weights and biases\n",
        "\n",
        "The weights and such are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:42.972699Z",
          "start_time": "2021-05-26T22:26:42.963913Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZMUnv5tap1I",
        "outputId": "a61927bc-cef8-4983-85fc-a5323a545725"
      },
      "source": [
        "print(model.fc1.weight)\n",
        "print(model.fc1.bias)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0305, -0.0061,  0.0236,  ...,  0.0022, -0.0082, -0.0102],\n",
            "        [-0.0158, -0.0244, -0.0006,  ...,  0.0060,  0.0128,  0.0119],\n",
            "        [ 0.0010, -0.0162,  0.0351,  ...,  0.0094,  0.0131, -0.0260],\n",
            "        [-0.0040, -0.0120,  0.0092,  ...,  0.0237,  0.0019, -0.0277]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0335,  0.0125,  0.0115,  0.0241], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2tqGndRap1K"
      },
      "source": [
        "For custom initialization, we want to modify these tensors in place. These are actually autograd *Variables*, so we need to get back the actual tensors with `model.fc1.weight.data`. Once we have the tensors, we can fill them with zeros (for biases) or random normal values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:43.889729Z",
          "start_time": "2021-05-26T22:26:43.883940Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X22HaItgap1L",
        "outputId": "fadc9530-7814-47f0-bc98-5541d44c0bee"
      },
      "source": [
        "# Set biases to all zeros\n",
        "model.fc1.bias.data.fill_(0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.084097Z",
          "start_time": "2021-05-26T22:26:44.076738Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2bnCs6gap1M",
        "outputId": "4452986d-d070-4f36-8cfd-26b458a20eb6"
      },
      "source": [
        "# sample from random normal with standard dev = 0.01\n",
        "model.fc1.weight.data.normal_(std=0.01)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0007, -0.0045, -0.0086,  ..., -0.0027,  0.0178,  0.0081],\n",
              "        [ 0.0041, -0.0153,  0.0039,  ..., -0.0025, -0.0059, -0.0079],\n",
              "        [ 0.0277, -0.0014,  0.0020,  ...,  0.0208,  0.0076, -0.0041],\n",
              "        [-0.0111, -0.0226,  0.0131,  ...,  0.0093, -0.0156, -0.0017]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-3VcP7Sap1O"
      },
      "source": [
        "### STEP 1: Forward pass\n",
        "\n",
        "Now that we have a network, let's see what happens when we pass in an image. This is called the forward pass. We're going to convert the image data into a tensor, then pass it through the operations defined by the network architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.506324Z",
          "start_time": "2021-05-26T22:26:44.491847Z"
        },
        "id": "RACTpv_7ap1P"
      },
      "source": [
        "# Grab some data \n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.596541Z",
          "start_time": "2021-05-26T22:26:44.594169Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJpt8NAkap1Q",
        "outputId": "01925301-b24d-4877-8c1d-6bc0e70a1b23"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 1, 28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:44.851894Z",
          "start_time": "2021-05-26T22:26:44.845888Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSk-MmQoap1R",
        "outputId": "04903009-8322-40d8-b8bb-fa47335ddcfd"
      },
      "source": [
        "model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=4, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=4, out_features=4, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (output): Linear(in_features=4, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:46.121246Z",
          "start_time": "2021-05-26T22:26:46.112022Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDHVSGOTap1S",
        "outputId": "ff89fab6-6d8c-4f7c-ccbd-519aab6df674"
      },
      "source": [
        "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "# or images.resize_(images.shape[0], 1, 784) to not automatically get batch size"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]],\n",
              "\n",
              "        [[-1., -1., -1.,  ..., -1., -1., -1.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:46.519895Z",
          "start_time": "2021-05-26T22:26:46.514137Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ktvi4ZPap1T",
        "outputId": "157c23a4-6cc0-4331-cb84-3c53dcd573c6"
      },
      "source": [
        "img_idx = 0\n",
        "images[img_idx,:].shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:47.945952Z",
          "start_time": "2021-05-26T22:26:47.888846Z"
        },
        "id": "dvBI9pCwap1V"
      },
      "source": [
        "# Forward pass through the network\n",
        "img_idx = 0\n",
        "ps = model(images[img_idx,:])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:50.561845Z",
          "start_time": "2021-05-26T22:26:50.411449Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "YWOXT9KVap1V",
        "outputId": "4266ed64-3511-420d-f579-e3d3348a59ba"
      },
      "source": [
        "img = images[img_idx]\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7nl8Bdhap1X"
      },
      "source": [
        "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, all the weights are random!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3mFFggPap1Y"
      },
      "source": [
        "# Training Neural Networks\n",
        "\n",
        "The network we built isn't so smart, it doesn't know anything about our handwritten digits. Neural networks with non-linear activations work like universal function approximators. There is some function that maps your input to the output. For example, images of handwritten digits to class probabilities. The power of neural networks is that we can train them to approximate this function, and basically any function given enough data and compute time.\n",
        "\n",
        "<img src=\"assets/function_approx.png\" width=500px>\n",
        "\n",
        "At first the network is naive, it doesn't know the function mapping the inputs to the outputs. We train the network by showing it examples of real data, then adjusting the network parameters such that it approximates this function.\n",
        "\n",
        "To find these parameters, we need to know how poorly the network is predicting the real outputs. For this we calculate a **loss function** (also called the cost), a measure of our prediction error. For example, the mean squared loss is often used in regression and binary classification problems\n",
        "\n",
        "$$\n",
        "\\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
        "$$\n",
        "\n",
        "where $n$ is the number of training examples, $y_i$ are the true labels, and $\\hat{y}_i$ are the predicted labels.\n",
        "\n",
        "By minimizing this loss with respect to the network parameters, we can find configurations where the loss is at a minimum and the network is able to predict the correct labels with high accuracy. We find this minimum using a process called **gradient descent**. The gradient is the slope of the loss function and points in the direction of fastest change. To get to the minimum in the least amount of time, we then want to follow the gradient (downwards). You can think of this like descending a mountain by following the steepest slope to the base.\n",
        "\n",
        "<img src='assets/gradient_descent.png' width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X63Iv-FKap1Z"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "For single layer networks, gradient descent is simple to implement. However, it's more complicated for deeper, multilayer neural networks like the one we've built. Complicated enough that it took about 30 years before researchers figured out how to train multilayer networks, although it's straightforward once you learn about it. \n",
        "\n",
        "This is done through **backpropagation** which is really just an application of the chain rule from calculus. It's easiest to understand if we convert a two layer network into a graph representation.\n",
        "\n",
        "<img src='assets/w1_backprop_graph.png' width=400px>\n",
        "\n",
        "In the forward pass through the network, our data and operations go from right to left here. To train the weights with gradient descent, we propagate the gradient of the cost backwards through the network. Mathematically, this is really just calculating the gradient of the loss with respect to the weights using the chain rule.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\ell}{\\partial w_1} = \\frac{\\partial l_1}{\\partial w_1} \\frac{\\partial s}{\\partial l_1} \\frac{\\partial l_2}{\\partial s} \\frac{\\partial \\ell}{\\partial l_2}\n",
        "$$\n",
        "\n",
        "We update our weights using this gradient with some learning rate $\\alpha$. \n",
        "\n",
        "$$\n",
        "w^\\prime = w - \\alpha \\frac{\\partial \\ell}{\\partial w}\n",
        "$$\n",
        "\n",
        "The learning rate is set such that the weight update steps are small enough that the iterative method settles in a minimum.\n",
        "\n",
        "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
        "\n",
        "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSbv8_J9ap1l"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Torch provides a module, `autograd`, for automatically calculating the gradient of tensors. It does this by keeping track of operations performed on tensors. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n",
        "\n",
        "You can turn off gradients for a block of code with the `torch.no_grad()` content:\n",
        "```python\n",
        "x = torch.zeros(1, requires_grad=True)\n",
        ">>> with torch.no_grad():\n",
        "...     y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "\n",
        "Also, you can turn on or off gradients altogether with `torch.set_grad_enabled(True|False)`.\n",
        "\n",
        "The gradients are computed with respect to some variable `z` with `z.backward()`. This does a backward pass through the operations that created `z`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:52.867509Z",
          "start_time": "2021-05-26T22:26:52.860629Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz6_RAagap1m",
        "outputId": "3d1bb217-94bc-4c53-d5e3-1b73e0876824"
      },
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.5746, -0.1783],\n",
            "        [-0.8114, -0.4971]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:53.383436Z",
          "start_time": "2021-05-26T22:26:53.375536Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiJ3BtnWap1n",
        "outputId": "994127b0-629c-4a70-f55f-68b8aa4f9219"
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2.4794, 0.0318],\n",
            "        [0.6584, 0.2471]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqX7XBgcap1o"
      },
      "source": [
        "Below we can see the operation that created `y`, a power operation `PowBackward0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:53.870654Z",
          "start_time": "2021-05-26T22:26:53.867424Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC0N1hqjap1p",
        "outputId": "bf9a96b2-8f4b-4f91-8b29-5e28c11abc8c"
      },
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7f1c55592050>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCDy-8_vap1q"
      },
      "source": [
        "The autgrad module keeps track of these operations and knows how to calculate the gradient for each one. In this way, it's able to calculate the gradients for a chain of operations, with respect to any one tensor. Let's reduce the tensor `y` to a scalar value, the mean."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:54.831912Z",
          "start_time": "2021-05-26T22:26:54.824631Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y38BV13eap1r",
        "outputId": "62e80b43-52c7-47d4-c0c2-4c954d83a095"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8542, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmAZBElcap1t"
      },
      "source": [
        "You can check the gradients for `x` and `y` but they are empty currently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:55.546143Z",
          "start_time": "2021-05-26T22:26:55.541213Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vbaQXugap1t",
        "outputId": "b2f67ba1-e6ed-48d9-ef9d-710d133889fb"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXn4Wn1uap1u"
      },
      "source": [
        "To calculate the gradients, you need to run the `.backward` method on a Variable, `z` for example. This will calculate the gradient for `z` with respect to `x`\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:56.607560Z",
          "start_time": "2021-05-26T22:26:56.594993Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZVu4iJ-ap1v",
        "outputId": "90b798f1-e50f-48cb-edcb-04acb958cf06"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7873, -0.0892],\n",
            "        [-0.4057, -0.2486]])\n",
            "tensor([[ 0.7873, -0.0892],\n",
            "        [-0.4057, -0.2486]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib4AFaNhap1w"
      },
      "source": [
        "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the weights with respect to the cost. With PyTorch, we run data forward through the network to calculate the cost, then, go backwards to calculate the gradients with respect to the cost. Once we have the gradients we can make a gradient descent step. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6V3uQPHap1x"
      },
      "source": [
        "I'll build a network with `nn.Sequential` here. Only difference from the last part is I'm not actually using softmax on the output, but instead just using the raw output from the last layer. This is because the output from softmax is a probability distribution. Often, the output will have values really close to zero or really close to one. Due to [inaccuracies with representing numbers as floating points](https://docs.python.org/3/tutorial/floatingpoint.html), computations with a softmax output can lose accuracy and become unstable. To get around this, we'll use the raw output, called the **logits**, to calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:56.944759Z",
          "start_time": "2021-05-26T22:26:56.936939Z"
        },
        "id": "2Ewh7Yr_ap1y"
      },
      "source": [
        "# Hyperparameters for our network\n",
        "input_size   = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size  = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('logits', nn.Linear(hidden_sizes[1], output_size))]))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdp66W9-ap1y"
      },
      "source": [
        "## Training the network!\n",
        "\n",
        "The first thing we need to do for training is define our loss function. In PyTorch, you'll usually see this as `criterion`. Here we're using softmax output, so we want to use `criterion = nn.CrossEntropyLoss()` as our loss. Later when training, you use `loss = criterion(output, targets)` to calculate the actual loss.\n",
        "\n",
        "We also need to define the optimizer we're using, SGD or Adam, or something along those lines. Here I'll just use SGD with `torch.optim.SGD`, passing in the network parameters and the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:26:57.317614Z",
          "start_time": "2021-05-26T22:26:57.313022Z"
        },
        "id": "NhiVBaRiap1z"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWyrnChpap10"
      },
      "source": [
        "First, let's consider just one learning step before looping through all the data. The general process with PyTorch:\n",
        "\n",
        "* Make a forward pass through the network to get the logits \n",
        "* Use the logits to calculate the loss\n",
        "* Perform a backward pass through the network with `loss.backward()` to calculate the gradients\n",
        "* Take a step with the optimizer to update the weights\n",
        "\n",
        "Below I'll go through one training step and print out the weights and gradients so you can see how it changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:07.408433Z",
          "start_time": "2021-05-26T22:27:07.373358Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlAalVdzap11",
        "outputId": "4b31dd3a-d321-4149-91b0-bd313c3effc8"
      },
      "source": [
        "print('Initial weights - ', model.fc1.weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(16, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model.forward(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model.fc1.weight.grad)\n",
        "optimizer.step()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0115,  0.0185,  0.0182,  ...,  0.0277, -0.0019, -0.0197],\n",
            "        [ 0.0207, -0.0085,  0.0200,  ...,  0.0160, -0.0259,  0.0040],\n",
            "        [ 0.0127,  0.0337,  0.0222,  ...,  0.0193, -0.0196,  0.0345],\n",
            "        ...,\n",
            "        [ 0.0135,  0.0323, -0.0056,  ..., -0.0168, -0.0051,  0.0285],\n",
            "        [-0.0098,  0.0020,  0.0115,  ..., -0.0216, -0.0159, -0.0194],\n",
            "        [-0.0096, -0.0213,  0.0311,  ..., -0.0180,  0.0052, -0.0254]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0022,  0.0022,  0.0022,  ...,  0.0022,  0.0022,  0.0022],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0016,  0.0016,  0.0016,  ...,  0.0016,  0.0016,  0.0016],\n",
            "        ...,\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
            "        [-0.0023, -0.0023, -0.0023,  ..., -0.0023, -0.0023, -0.0023]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:07.915247Z",
          "start_time": "2021-05-26T22:27:07.908155Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD1G7dkVap12",
        "outputId": "f1f9d74e-1b4b-4efb-aae7-68c8db3acb06"
      },
      "source": [
        "print('Updated weights - ', model.fc1.weight)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0115,  0.0185,  0.0182,  ...,  0.0277, -0.0020, -0.0198],\n",
            "        [ 0.0207, -0.0085,  0.0200,  ...,  0.0160, -0.0259,  0.0040],\n",
            "        [ 0.0127,  0.0337,  0.0221,  ...,  0.0192, -0.0196,  0.0344],\n",
            "        ...,\n",
            "        [ 0.0135,  0.0323, -0.0056,  ..., -0.0168, -0.0051,  0.0285],\n",
            "        [-0.0098,  0.0020,  0.0116,  ..., -0.0216, -0.0159, -0.0193],\n",
            "        [-0.0095, -0.0213,  0.0312,  ..., -0.0180,  0.0052, -0.0254]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMff1i5eap13"
      },
      "source": [
        "### Training for real\n",
        "\n",
        "Now we'll put this algorithm into a loop so we can go through all the images. This is fairly straightforward. We'll loop through the mini-batches in our dataset, pass the data through the network to calculate the losses, get the gradients, then run the optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:08.816179Z",
          "start_time": "2021-05-26T22:27:08.812807Z"
        },
        "id": "XELGKbVdap14"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.003)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:27:36.083537Z",
          "start_time": "2021-05-26T22:27:09.280769Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAwEFQ02ap14",
        "outputId": "6897159a-6549-43f6-c3c0-7d5fa5c0f087"
      },
      "source": [
        "epochs = 3\n",
        "print_every = 40\n",
        "\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    print(f\"Epoch: {e+1}/{epochs}\")\n",
        "\n",
        "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
        "\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images.resize_(images.size()[0], 784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model.forward(images)   # 1) Forward pass\n",
        "        loss = criterion(output, labels) # 2) Compute loss\n",
        "        loss.backward()                  # 3) Backward pass\n",
        "        optimizer.step()                 # 4) Update model\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % print_every == 0:\n",
        "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
        "            running_loss = 0 "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3\n",
            "\tIteration: 0\t Loss: 0.0586\n",
            "\tIteration: 40\t Loss: 2.2978\n",
            "\tIteration: 80\t Loss: 2.2893\n",
            "\tIteration: 120\t Loss: 2.2678\n",
            "\tIteration: 160\t Loss: 2.2471\n",
            "\tIteration: 200\t Loss: 2.2319\n",
            "\tIteration: 240\t Loss: 2.2144\n",
            "\tIteration: 280\t Loss: 2.1966\n",
            "\tIteration: 320\t Loss: 2.1543\n",
            "\tIteration: 360\t Loss: 2.1374\n",
            "\tIteration: 400\t Loss: 2.0969\n",
            "\tIteration: 440\t Loss: 2.0658\n",
            "\tIteration: 480\t Loss: 2.0039\n",
            "\tIteration: 520\t Loss: 1.9729\n",
            "\tIteration: 560\t Loss: 1.9319\n",
            "\tIteration: 600\t Loss: 1.9024\n",
            "\tIteration: 640\t Loss: 1.8331\n",
            "\tIteration: 680\t Loss: 1.7822\n",
            "\tIteration: 720\t Loss: 1.7371\n",
            "\tIteration: 760\t Loss: 1.6261\n",
            "\tIteration: 800\t Loss: 1.5880\n",
            "\tIteration: 840\t Loss: 1.5497\n",
            "\tIteration: 880\t Loss: 1.4818\n",
            "\tIteration: 920\t Loss: 1.4216\n",
            "\tIteration: 960\t Loss: 1.3797\n",
            "\tIteration: 1000\t Loss: 1.3029\n",
            "\tIteration: 1040\t Loss: 1.2131\n",
            "\tIteration: 1080\t Loss: 1.1349\n",
            "\tIteration: 1120\t Loss: 1.1074\n",
            "\tIteration: 1160\t Loss: 1.0410\n",
            "\tIteration: 1200\t Loss: 1.0419\n",
            "\tIteration: 1240\t Loss: 0.9879\n",
            "\tIteration: 1280\t Loss: 0.9534\n",
            "\tIteration: 1320\t Loss: 0.9095\n",
            "\tIteration: 1360\t Loss: 0.8812\n",
            "\tIteration: 1400\t Loss: 0.8866\n",
            "\tIteration: 1440\t Loss: 0.8198\n",
            "\tIteration: 1480\t Loss: 0.8827\n",
            "\tIteration: 1520\t Loss: 0.8318\n",
            "\tIteration: 1560\t Loss: 0.7824\n",
            "\tIteration: 1600\t Loss: 0.7898\n",
            "\tIteration: 1640\t Loss: 0.7471\n",
            "\tIteration: 1680\t Loss: 0.7449\n",
            "\tIteration: 1720\t Loss: 0.7452\n",
            "\tIteration: 1760\t Loss: 0.6605\n",
            "\tIteration: 1800\t Loss: 0.6261\n",
            "\tIteration: 1840\t Loss: 0.6494\n",
            "\tIteration: 1880\t Loss: 0.6699\n",
            "\tIteration: 1920\t Loss: 0.6148\n",
            "\tIteration: 1960\t Loss: 0.6607\n",
            "\tIteration: 2000\t Loss: 0.5978\n",
            "\tIteration: 2040\t Loss: 0.5529\n",
            "\tIteration: 2080\t Loss: 0.6435\n",
            "\tIteration: 2120\t Loss: 0.5551\n",
            "\tIteration: 2160\t Loss: 0.6177\n",
            "\tIteration: 2200\t Loss: 0.5420\n",
            "\tIteration: 2240\t Loss: 0.5108\n",
            "\tIteration: 2280\t Loss: 0.5479\n",
            "\tIteration: 2320\t Loss: 0.5300\n",
            "\tIteration: 2360\t Loss: 0.5094\n",
            "\tIteration: 2400\t Loss: 0.4504\n",
            "\tIteration: 2440\t Loss: 0.5559\n",
            "\tIteration: 2480\t Loss: 0.4645\n",
            "\tIteration: 2520\t Loss: 0.5341\n",
            "\tIteration: 2560\t Loss: 0.5091\n",
            "\tIteration: 2600\t Loss: 0.4722\n",
            "\tIteration: 2640\t Loss: 0.4053\n",
            "\tIteration: 2680\t Loss: 0.4865\n",
            "\tIteration: 2720\t Loss: 0.5285\n",
            "\tIteration: 2760\t Loss: 0.4502\n",
            "\tIteration: 2800\t Loss: 0.4384\n",
            "\tIteration: 2840\t Loss: 0.4794\n",
            "\tIteration: 2880\t Loss: 0.4938\n",
            "\tIteration: 2920\t Loss: 0.4473\n",
            "\tIteration: 2960\t Loss: 0.3937\n",
            "\tIteration: 3000\t Loss: 0.4592\n",
            "\tIteration: 3040\t Loss: 0.4544\n",
            "\tIteration: 3080\t Loss: 0.4985\n",
            "\tIteration: 3120\t Loss: 0.4885\n",
            "\tIteration: 3160\t Loss: 0.4589\n",
            "\tIteration: 3200\t Loss: 0.4537\n",
            "\tIteration: 3240\t Loss: 0.4380\n",
            "\tIteration: 3280\t Loss: 0.5693\n",
            "\tIteration: 3320\t Loss: 0.4021\n",
            "\tIteration: 3360\t Loss: 0.4384\n",
            "\tIteration: 3400\t Loss: 0.4893\n",
            "\tIteration: 3440\t Loss: 0.4564\n",
            "\tIteration: 3480\t Loss: 0.4654\n",
            "\tIteration: 3520\t Loss: 0.4249\n",
            "\tIteration: 3560\t Loss: 0.4573\n",
            "\tIteration: 3600\t Loss: 0.4491\n",
            "\tIteration: 3640\t Loss: 0.4225\n",
            "\tIteration: 3680\t Loss: 0.3774\n",
            "\tIteration: 3720\t Loss: 0.4633\n",
            "Epoch: 2/3\n",
            "\tIteration: 0\t Loss: 0.0122\n",
            "\tIteration: 40\t Loss: 0.3984\n",
            "\tIteration: 80\t Loss: 0.4420\n",
            "\tIteration: 120\t Loss: 0.3708\n",
            "\tIteration: 160\t Loss: 0.4094\n",
            "\tIteration: 200\t Loss: 0.4120\n",
            "\tIteration: 240\t Loss: 0.4111\n",
            "\tIteration: 280\t Loss: 0.3750\n",
            "\tIteration: 320\t Loss: 0.3946\n",
            "\tIteration: 360\t Loss: 0.4395\n",
            "\tIteration: 400\t Loss: 0.4090\n",
            "\tIteration: 440\t Loss: 0.4342\n",
            "\tIteration: 480\t Loss: 0.3932\n",
            "\tIteration: 520\t Loss: 0.3770\n",
            "\tIteration: 560\t Loss: 0.3876\n",
            "\tIteration: 600\t Loss: 0.4279\n",
            "\tIteration: 640\t Loss: 0.3919\n",
            "\tIteration: 680\t Loss: 0.3599\n",
            "\tIteration: 720\t Loss: 0.3694\n",
            "\tIteration: 760\t Loss: 0.3943\n",
            "\tIteration: 800\t Loss: 0.3921\n",
            "\tIteration: 840\t Loss: 0.4307\n",
            "\tIteration: 880\t Loss: 0.3576\n",
            "\tIteration: 920\t Loss: 0.3464\n",
            "\tIteration: 960\t Loss: 0.3684\n",
            "\tIteration: 1000\t Loss: 0.4467\n",
            "\tIteration: 1040\t Loss: 0.3306\n",
            "\tIteration: 1080\t Loss: 0.4055\n",
            "\tIteration: 1120\t Loss: 0.3862\n",
            "\tIteration: 1160\t Loss: 0.2772\n",
            "\tIteration: 1200\t Loss: 0.3894\n",
            "\tIteration: 1240\t Loss: 0.3641\n",
            "\tIteration: 1280\t Loss: 0.3724\n",
            "\tIteration: 1320\t Loss: 0.3521\n",
            "\tIteration: 1360\t Loss: 0.3395\n",
            "\tIteration: 1400\t Loss: 0.3337\n",
            "\tIteration: 1440\t Loss: 0.3334\n",
            "\tIteration: 1480\t Loss: 0.3803\n",
            "\tIteration: 1520\t Loss: 0.4081\n",
            "\tIteration: 1560\t Loss: 0.4037\n",
            "\tIteration: 1600\t Loss: 0.3531\n",
            "\tIteration: 1640\t Loss: 0.3179\n",
            "\tIteration: 1680\t Loss: 0.4091\n",
            "\tIteration: 1720\t Loss: 0.3928\n",
            "\tIteration: 1760\t Loss: 0.3813\n",
            "\tIteration: 1800\t Loss: 0.3516\n",
            "\tIteration: 1840\t Loss: 0.4282\n",
            "\tIteration: 1880\t Loss: 0.4066\n",
            "\tIteration: 1920\t Loss: 0.3659\n",
            "\tIteration: 1960\t Loss: 0.3175\n",
            "\tIteration: 2000\t Loss: 0.3201\n",
            "\tIteration: 2040\t Loss: 0.4043\n",
            "\tIteration: 2080\t Loss: 0.3977\n",
            "\tIteration: 2120\t Loss: 0.3376\n",
            "\tIteration: 2160\t Loss: 0.3330\n",
            "\tIteration: 2200\t Loss: 0.3017\n",
            "\tIteration: 2240\t Loss: 0.4212\n",
            "\tIteration: 2280\t Loss: 0.3453\n",
            "\tIteration: 2320\t Loss: 0.3210\n",
            "\tIteration: 2360\t Loss: 0.3232\n",
            "\tIteration: 2400\t Loss: 0.3358\n",
            "\tIteration: 2440\t Loss: 0.3277\n",
            "\tIteration: 2480\t Loss: 0.3478\n",
            "\tIteration: 2520\t Loss: 0.3476\n",
            "\tIteration: 2560\t Loss: 0.3315\n",
            "\tIteration: 2600\t Loss: 0.3845\n",
            "\tIteration: 2640\t Loss: 0.3309\n",
            "\tIteration: 2680\t Loss: 0.3228\n",
            "\tIteration: 2720\t Loss: 0.3033\n",
            "\tIteration: 2760\t Loss: 0.3265\n",
            "\tIteration: 2800\t Loss: 0.2863\n",
            "\tIteration: 2840\t Loss: 0.3613\n",
            "\tIteration: 2880\t Loss: 0.3305\n",
            "\tIteration: 2920\t Loss: 0.3056\n",
            "\tIteration: 2960\t Loss: 0.3403\n",
            "\tIteration: 3000\t Loss: 0.3426\n",
            "\tIteration: 3040\t Loss: 0.3485\n",
            "\tIteration: 3080\t Loss: 0.2844\n",
            "\tIteration: 3120\t Loss: 0.3047\n",
            "\tIteration: 3160\t Loss: 0.3288\n",
            "\tIteration: 3200\t Loss: 0.3078\n",
            "\tIteration: 3240\t Loss: 0.3124\n",
            "\tIteration: 3280\t Loss: 0.3604\n",
            "\tIteration: 3320\t Loss: 0.3264\n",
            "\tIteration: 3360\t Loss: 0.3779\n",
            "\tIteration: 3400\t Loss: 0.3996\n",
            "\tIteration: 3440\t Loss: 0.3078\n",
            "\tIteration: 3480\t Loss: 0.3388\n",
            "\tIteration: 3520\t Loss: 0.3690\n",
            "\tIteration: 3560\t Loss: 0.4051\n",
            "\tIteration: 3600\t Loss: 0.3720\n",
            "\tIteration: 3640\t Loss: 0.3193\n",
            "\tIteration: 3680\t Loss: 0.3214\n",
            "\tIteration: 3720\t Loss: 0.3340\n",
            "Epoch: 3/3\n",
            "\tIteration: 0\t Loss: 0.0070\n",
            "\tIteration: 40\t Loss: 0.3010\n",
            "\tIteration: 80\t Loss: 0.3121\n",
            "\tIteration: 120\t Loss: 0.3248\n",
            "\tIteration: 160\t Loss: 0.3402\n",
            "\tIteration: 200\t Loss: 0.2805\n",
            "\tIteration: 240\t Loss: 0.3997\n",
            "\tIteration: 280\t Loss: 0.2853\n",
            "\tIteration: 320\t Loss: 0.2673\n",
            "\tIteration: 360\t Loss: 0.3582\n",
            "\tIteration: 400\t Loss: 0.2476\n",
            "\tIteration: 440\t Loss: 0.3243\n",
            "\tIteration: 480\t Loss: 0.3165\n",
            "\tIteration: 520\t Loss: 0.2974\n",
            "\tIteration: 560\t Loss: 0.3284\n",
            "\tIteration: 600\t Loss: 0.3324\n",
            "\tIteration: 640\t Loss: 0.2717\n",
            "\tIteration: 680\t Loss: 0.3202\n",
            "\tIteration: 720\t Loss: 0.3262\n",
            "\tIteration: 760\t Loss: 0.3444\n",
            "\tIteration: 800\t Loss: 0.3349\n",
            "\tIteration: 840\t Loss: 0.3303\n",
            "\tIteration: 880\t Loss: 0.3378\n",
            "\tIteration: 920\t Loss: 0.3272\n",
            "\tIteration: 960\t Loss: 0.2855\n",
            "\tIteration: 1000\t Loss: 0.2828\n",
            "\tIteration: 1040\t Loss: 0.2922\n",
            "\tIteration: 1080\t Loss: 0.3429\n",
            "\tIteration: 1120\t Loss: 0.3453\n",
            "\tIteration: 1160\t Loss: 0.3180\n",
            "\tIteration: 1200\t Loss: 0.3233\n",
            "\tIteration: 1240\t Loss: 0.2907\n",
            "\tIteration: 1280\t Loss: 0.3234\n",
            "\tIteration: 1320\t Loss: 0.3401\n",
            "\tIteration: 1360\t Loss: 0.3120\n",
            "\tIteration: 1400\t Loss: 0.3105\n",
            "\tIteration: 1440\t Loss: 0.3028\n",
            "\tIteration: 1480\t Loss: 0.2564\n",
            "\tIteration: 1520\t Loss: 0.2970\n",
            "\tIteration: 1560\t Loss: 0.3042\n",
            "\tIteration: 1600\t Loss: 0.3990\n",
            "\tIteration: 1640\t Loss: 0.2862\n",
            "\tIteration: 1680\t Loss: 0.2894\n",
            "\tIteration: 1720\t Loss: 0.3007\n",
            "\tIteration: 1760\t Loss: 0.3317\n",
            "\tIteration: 1800\t Loss: 0.2811\n",
            "\tIteration: 1840\t Loss: 0.3244\n",
            "\tIteration: 1880\t Loss: 0.3427\n",
            "\tIteration: 1920\t Loss: 0.2770\n",
            "\tIteration: 1960\t Loss: 0.3001\n",
            "\tIteration: 2000\t Loss: 0.2942\n",
            "\tIteration: 2040\t Loss: 0.3312\n",
            "\tIteration: 2080\t Loss: 0.2840\n",
            "\tIteration: 2120\t Loss: 0.2940\n",
            "\tIteration: 2160\t Loss: 0.3616\n",
            "\tIteration: 2200\t Loss: 0.3242\n",
            "\tIteration: 2240\t Loss: 0.3062\n",
            "\tIteration: 2280\t Loss: 0.3188\n",
            "\tIteration: 2320\t Loss: 0.3212\n",
            "\tIteration: 2360\t Loss: 0.2994\n",
            "\tIteration: 2400\t Loss: 0.2704\n",
            "\tIteration: 2440\t Loss: 0.2687\n",
            "\tIteration: 2480\t Loss: 0.3243\n",
            "\tIteration: 2520\t Loss: 0.3100\n",
            "\tIteration: 2560\t Loss: 0.2576\n",
            "\tIteration: 2600\t Loss: 0.2935\n",
            "\tIteration: 2640\t Loss: 0.2735\n",
            "\tIteration: 2680\t Loss: 0.3633\n",
            "\tIteration: 2720\t Loss: 0.2680\n",
            "\tIteration: 2760\t Loss: 0.3125\n",
            "\tIteration: 2800\t Loss: 0.2770\n",
            "\tIteration: 2840\t Loss: 0.3171\n",
            "\tIteration: 2880\t Loss: 0.2777\n",
            "\tIteration: 2920\t Loss: 0.2330\n",
            "\tIteration: 2960\t Loss: 0.3155\n",
            "\tIteration: 3000\t Loss: 0.3120\n",
            "\tIteration: 3040\t Loss: 0.2965\n",
            "\tIteration: 3080\t Loss: 0.2818\n",
            "\tIteration: 3120\t Loss: 0.2942\n",
            "\tIteration: 3160\t Loss: 0.3021\n",
            "\tIteration: 3200\t Loss: 0.3484\n",
            "\tIteration: 3240\t Loss: 0.2634\n",
            "\tIteration: 3280\t Loss: 0.3341\n",
            "\tIteration: 3320\t Loss: 0.3202\n",
            "\tIteration: 3360\t Loss: 0.3149\n",
            "\tIteration: 3400\t Loss: 0.2579\n",
            "\tIteration: 3440\t Loss: 0.3100\n",
            "\tIteration: 3480\t Loss: 0.3073\n",
            "\tIteration: 3520\t Loss: 0.2754\n",
            "\tIteration: 3560\t Loss: 0.3196\n",
            "\tIteration: 3600\t Loss: 0.2373\n",
            "\tIteration: 3640\t Loss: 0.2645\n",
            "\tIteration: 3680\t Loss: 0.2963\n",
            "\tIteration: 3720\t Loss: 0.3519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SseuAhReap15"
      },
      "source": [
        "With the network trained, we can check out it's predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:30:00.206666Z",
          "start_time": "2021-05-26T22:29:59.954325Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "MnbxoNslap16",
        "outputId": "3eee04ba-fc23-4225-b494-ed2a75cc6421"
      },
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logits = model.forward(img)\n",
        "\n",
        "# Output of the network are logits, need to take softmax for probabilities\n",
        "ps = F.softmax(logits, dim=1)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNci7XU4ap17"
      },
      "source": [
        "Now our network is brilliant. It can accurately predict the digits in our images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k885vZxRap18"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "    <h2 align=\"center\" style=\"color:#01ff84\">EMNIST Classification: Exercise</h2>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1yNxYnwap18"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 1:</h3>\n",
        "  <p>Now it's your turn to build a simple network, use any method I've covered so far. In the next notebook, you'll learn how to train a network so it can make good predictions.</p>\n",
        "  <p>Build a network to classify the MNIST images with 3 hidden layers. Use 16 units in the first hidden layer, 32 units in the second layer, and 8 units in the third layer. Each hidden layer should have a ReLU activation function, and use softmax on the output layer.</p>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmSTBPNmap19",
        "outputId": "3d6ce9f6-6e3d-40a5-a41b-aa397c34da45"
      },
      "source": [
        "## TODO: Your network here\n",
        "\n",
        "# Hyperparameters for our network\n",
        "input_size   = 784\n",
        "hidden_sizes = [16, 32, 8]\n",
        "output_size  = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(OrderedDict([\n",
        "          ('fc1', nn.Linear(input_size, hidden_sizes[0])),\n",
        "          ('relu1', nn.ReLU()),\n",
        "          ('fc2', nn.Linear(hidden_sizes[0], hidden_sizes[1])),\n",
        "          ('relu2', nn.ReLU()),\n",
        "          ('fc3', nn.Linear(hidden_sizes[1], hidden_sizes[2])),\n",
        "          ('relu3', nn.ReLU()),\n",
        "          ('output', nn.Linear(hidden_sizes[2], output_size)),\n",
        "          ('softmax', nn.Softmax(dim=1))]))\n",
        "\n",
        "model"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (fc1): Linear(in_features=784, out_features=16, bias=True)\n",
              "  (relu1): ReLU()\n",
              "  (fc2): Linear(in_features=16, out_features=32, bias=True)\n",
              "  (relu2): ReLU()\n",
              "  (fc3): Linear(in_features=32, out_features=8, bias=True)\n",
              "  (relu3): ReLU()\n",
              "  (output): Linear(in_features=8, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "EmfUy4Hjap1-",
        "outputId": "f7b69741-d73f-4809-89c8-27f2949ba204"
      },
      "source": [
        "# Run this cell with your model to make sure it works\n",
        "# Forward pass through the network and display output\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:]) \n",
        "\n",
        "view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-82APvFap2A"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 2:</h3>\n",
        "  <p>Train your network implementing the Pytorch training loop and <strong style=\"color:#01ff84\">after each epoch, use the model for predicting the test (validation) MNIST data.</strong></p>\n",
        "  <p>Note: If your model does not fit with the final softmax layer, you can remove this layer.</p>\n",
        "  <p>Hint: <a href=\"https://discuss.pytorch.org/t/training-loop-checking-validation-accuracy/78399\">Training loop checking validation accuracy\n",
        "</a></p>\n",
        "  <p>Research about <code>model.train()</code>, <code>model.eval()</code> and <code>with torch.no_grad()</code> in Pytorch.\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5zDyqIUap2A",
        "outputId": "56643b94-b696-436d-955e-7e61e967fca5"
      },
      "source": [
        "## TODO: Your training loop here\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.03)\n",
        "\n",
        "epochs = 3\n",
        "print_every = 40\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "    running_loss = 0\n",
        "\n",
        "    print(f\"Epoch: {e+1}/{epochs}\")\n",
        "\n",
        "    for i, (images, labels) in enumerate(iter(trainloader)):\n",
        "\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images.resize_(images.size()[0],  784)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #model.train()\n",
        "\n",
        "        output = model.forward(images)   # 1) Forward pass\n",
        "        loss = criterion(output, labels) # 2) Compute loss\n",
        "        loss.backward()                  # 3) Backward pass\n",
        "        optimizer.step()                 # 4) Update model\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if i % print_every == 0:\n",
        "            print(f\"\\tIteration: {i}\\t Loss: {running_loss/print_every:.4f}\")\n",
        "            running_loss = 0 \n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for i, (images, labels) in enumerate(iter(testloader)):\n",
        "            #images, labels = data\n",
        "            # calculate outputs by running images through the network\n",
        "            images.resize_(images.size()[0],  784)\n",
        "            outputs = model(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "        100 * correct / total))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/3\n",
            "\tIteration: 0\t Loss: 0.0576\n",
            "\tIteration: 40\t Loss: 2.3031\n",
            "\tIteration: 80\t Loss: 2.3036\n",
            "\tIteration: 120\t Loss: 2.3008\n",
            "\tIteration: 160\t Loss: 2.3018\n",
            "\tIteration: 200\t Loss: 2.3013\n",
            "\tIteration: 240\t Loss: 2.3015\n",
            "\tIteration: 280\t Loss: 2.3004\n",
            "\tIteration: 320\t Loss: 2.3005\n",
            "\tIteration: 360\t Loss: 2.3007\n",
            "\tIteration: 400\t Loss: 2.3011\n",
            "\tIteration: 440\t Loss: 2.3000\n",
            "\tIteration: 480\t Loss: 2.3013\n",
            "\tIteration: 520\t Loss: 2.2991\n",
            "\tIteration: 560\t Loss: 2.3006\n",
            "\tIteration: 600\t Loss: 2.2986\n",
            "\tIteration: 640\t Loss: 2.2986\n",
            "\tIteration: 680\t Loss: 2.2984\n",
            "\tIteration: 720\t Loss: 2.2981\n",
            "\tIteration: 760\t Loss: 2.2965\n",
            "\tIteration: 800\t Loss: 2.2971\n",
            "\tIteration: 840\t Loss: 2.2959\n",
            "\tIteration: 880\t Loss: 2.2942\n",
            "\tIteration: 920\t Loss: 2.2943\n",
            "\tIteration: 960\t Loss: 2.2935\n",
            "\tIteration: 1000\t Loss: 2.2918\n",
            "\tIteration: 1040\t Loss: 2.2913\n",
            "\tIteration: 1080\t Loss: 2.2892\n",
            "\tIteration: 1120\t Loss: 2.2875\n",
            "\tIteration: 1160\t Loss: 2.2851\n",
            "\tIteration: 1200\t Loss: 2.2799\n",
            "\tIteration: 1240\t Loss: 2.2745\n",
            "\tIteration: 1280\t Loss: 2.2680\n",
            "\tIteration: 1320\t Loss: 2.2579\n",
            "\tIteration: 1360\t Loss: 2.2590\n",
            "\tIteration: 1400\t Loss: 2.2412\n",
            "\tIteration: 1440\t Loss: 2.2451\n",
            "\tIteration: 1480\t Loss: 2.1972\n",
            "\tIteration: 1520\t Loss: 2.1811\n",
            "\tIteration: 1560\t Loss: 2.1900\n",
            "\tIteration: 1600\t Loss: 2.1569\n",
            "\tIteration: 1640\t Loss: 2.1679\n",
            "\tIteration: 1680\t Loss: 2.1536\n",
            "\tIteration: 1720\t Loss: 2.1571\n",
            "\tIteration: 1760\t Loss: 2.1545\n",
            "\tIteration: 1800\t Loss: 2.1444\n",
            "\tIteration: 1840\t Loss: 2.1436\n",
            "\tIteration: 1880\t Loss: 2.1076\n",
            "\tIteration: 1920\t Loss: 2.0736\n",
            "\tIteration: 1960\t Loss: 2.0642\n",
            "\tIteration: 2000\t Loss: 2.0892\n",
            "\tIteration: 2040\t Loss: 2.0536\n",
            "\tIteration: 2080\t Loss: 2.0333\n",
            "\tIteration: 2120\t Loss: 2.0143\n",
            "\tIteration: 2160\t Loss: 2.0276\n",
            "\tIteration: 2200\t Loss: 2.0316\n",
            "\tIteration: 2240\t Loss: 2.0090\n",
            "\tIteration: 2280\t Loss: 1.9934\n",
            "\tIteration: 2320\t Loss: 2.0022\n",
            "\tIteration: 2360\t Loss: 2.0009\n",
            "\tIteration: 2400\t Loss: 1.9787\n",
            "\tIteration: 2440\t Loss: 1.9701\n",
            "\tIteration: 2480\t Loss: 1.9748\n",
            "\tIteration: 2520\t Loss: 1.9685\n",
            "\tIteration: 2560\t Loss: 1.9588\n",
            "\tIteration: 2600\t Loss: 1.9115\n",
            "\tIteration: 2640\t Loss: 1.9215\n",
            "\tIteration: 2680\t Loss: 1.9220\n",
            "\tIteration: 2720\t Loss: 1.9328\n",
            "\tIteration: 2760\t Loss: 1.9202\n",
            "\tIteration: 2800\t Loss: 1.9223\n",
            "\tIteration: 2840\t Loss: 1.8878\n",
            "\tIteration: 2880\t Loss: 1.8820\n",
            "\tIteration: 2920\t Loss: 1.8954\n",
            "\tIteration: 2960\t Loss: 1.8961\n",
            "\tIteration: 3000\t Loss: 1.8872\n",
            "\tIteration: 3040\t Loss: 1.8900\n",
            "\tIteration: 3080\t Loss: 1.8535\n",
            "\tIteration: 3120\t Loss: 1.8781\n",
            "\tIteration: 3160\t Loss: 1.8706\n",
            "\tIteration: 3200\t Loss: 1.8566\n",
            "\tIteration: 3240\t Loss: 1.9034\n",
            "\tIteration: 3280\t Loss: 1.8380\n",
            "\tIteration: 3320\t Loss: 1.8477\n",
            "\tIteration: 3360\t Loss: 1.8551\n",
            "\tIteration: 3400\t Loss: 1.8435\n",
            "\tIteration: 3440\t Loss: 1.8659\n",
            "\tIteration: 3480\t Loss: 1.8542\n",
            "\tIteration: 3520\t Loss: 1.8475\n",
            "\tIteration: 3560\t Loss: 1.8585\n",
            "\tIteration: 3600\t Loss: 1.8456\n",
            "\tIteration: 3640\t Loss: 1.8500\n",
            "\tIteration: 3680\t Loss: 1.8935\n",
            "\tIteration: 3720\t Loss: 1.8498\n",
            "Accuracy of the network on the 10000 test images: 62 %\n",
            "Epoch: 2/3\n",
            "\tIteration: 0\t Loss: 0.0464\n",
            "\tIteration: 40\t Loss: 1.8628\n",
            "\tIteration: 80\t Loss: 1.8126\n",
            "\tIteration: 120\t Loss: 1.8414\n",
            "\tIteration: 160\t Loss: 1.8050\n",
            "\tIteration: 200\t Loss: 1.8483\n",
            "\tIteration: 240\t Loss: 1.8376\n",
            "\tIteration: 280\t Loss: 1.8340\n",
            "\tIteration: 320\t Loss: 1.8414\n",
            "\tIteration: 360\t Loss: 1.8560\n",
            "\tIteration: 400\t Loss: 1.7936\n",
            "\tIteration: 440\t Loss: 1.8355\n",
            "\tIteration: 480\t Loss: 1.8183\n",
            "\tIteration: 520\t Loss: 1.8440\n",
            "\tIteration: 560\t Loss: 1.8095\n",
            "\tIteration: 600\t Loss: 1.8393\n",
            "\tIteration: 640\t Loss: 1.8322\n",
            "\tIteration: 680\t Loss: 1.7902\n",
            "\tIteration: 720\t Loss: 1.8012\n",
            "\tIteration: 760\t Loss: 1.8041\n",
            "\tIteration: 800\t Loss: 1.7823\n",
            "\tIteration: 840\t Loss: 1.7840\n",
            "\tIteration: 880\t Loss: 1.7938\n",
            "\tIteration: 920\t Loss: 1.8047\n",
            "\tIteration: 960\t Loss: 1.7510\n",
            "\tIteration: 1000\t Loss: 1.7999\n",
            "\tIteration: 1040\t Loss: 1.8037\n",
            "\tIteration: 1080\t Loss: 1.7736\n",
            "\tIteration: 1120\t Loss: 1.7908\n",
            "\tIteration: 1160\t Loss: 1.7851\n",
            "\tIteration: 1200\t Loss: 1.7513\n",
            "\tIteration: 1240\t Loss: 1.7682\n",
            "\tIteration: 1280\t Loss: 1.7673\n",
            "\tIteration: 1320\t Loss: 1.7663\n",
            "\tIteration: 1360\t Loss: 1.7583\n",
            "\tIteration: 1400\t Loss: 1.7613\n",
            "\tIteration: 1440\t Loss: 1.7671\n",
            "\tIteration: 1480\t Loss: 1.7963\n",
            "\tIteration: 1520\t Loss: 1.7627\n",
            "\tIteration: 1560\t Loss: 1.7569\n",
            "\tIteration: 1600\t Loss: 1.7445\n",
            "\tIteration: 1640\t Loss: 1.7749\n",
            "\tIteration: 1680\t Loss: 1.7774\n",
            "\tIteration: 1720\t Loss: 1.7410\n",
            "\tIteration: 1760\t Loss: 1.7605\n",
            "\tIteration: 1800\t Loss: 1.7157\n",
            "\tIteration: 1840\t Loss: 1.7827\n",
            "\tIteration: 1880\t Loss: 1.7766\n",
            "\tIteration: 1920\t Loss: 1.8172\n",
            "\tIteration: 1960\t Loss: 1.7346\n",
            "\tIteration: 2000\t Loss: 1.7683\n",
            "\tIteration: 2040\t Loss: 1.7477\n",
            "\tIteration: 2080\t Loss: 1.7278\n",
            "\tIteration: 2120\t Loss: 1.7458\n",
            "\tIteration: 2160\t Loss: 1.7633\n",
            "\tIteration: 2200\t Loss: 1.7474\n",
            "\tIteration: 2240\t Loss: 1.7431\n",
            "\tIteration: 2280\t Loss: 1.7407\n",
            "\tIteration: 2320\t Loss: 1.7950\n",
            "\tIteration: 2360\t Loss: 1.7613\n",
            "\tIteration: 2400\t Loss: 1.7445\n",
            "\tIteration: 2440\t Loss: 1.7366\n",
            "\tIteration: 2480\t Loss: 1.7366\n",
            "\tIteration: 2520\t Loss: 1.7293\n",
            "\tIteration: 2560\t Loss: 1.7254\n",
            "\tIteration: 2600\t Loss: 1.7140\n",
            "\tIteration: 2640\t Loss: 1.7361\n",
            "\tIteration: 2680\t Loss: 1.7182\n",
            "\tIteration: 2720\t Loss: 1.7153\n",
            "\tIteration: 2760\t Loss: 1.7446\n",
            "\tIteration: 2800\t Loss: 1.7206\n",
            "\tIteration: 2840\t Loss: 1.7305\n",
            "\tIteration: 2880\t Loss: 1.7142\n",
            "\tIteration: 2920\t Loss: 1.7216\n",
            "\tIteration: 2960\t Loss: 1.7236\n",
            "\tIteration: 3000\t Loss: 1.7054\n",
            "\tIteration: 3040\t Loss: 1.7242\n",
            "\tIteration: 3080\t Loss: 1.7084\n",
            "\tIteration: 3120\t Loss: 1.7076\n",
            "\tIteration: 3160\t Loss: 1.7215\n",
            "\tIteration: 3200\t Loss: 1.7137\n",
            "\tIteration: 3240\t Loss: 1.7385\n",
            "\tIteration: 3280\t Loss: 1.6812\n",
            "\tIteration: 3320\t Loss: 1.6949\n",
            "\tIteration: 3360\t Loss: 1.7011\n",
            "\tIteration: 3400\t Loss: 1.7291\n",
            "\tIteration: 3440\t Loss: 1.7079\n",
            "\tIteration: 3480\t Loss: 1.6891\n",
            "\tIteration: 3520\t Loss: 1.7022\n",
            "\tIteration: 3560\t Loss: 1.7115\n",
            "\tIteration: 3600\t Loss: 1.6725\n",
            "\tIteration: 3640\t Loss: 1.6805\n",
            "\tIteration: 3680\t Loss: 1.6980\n",
            "\tIteration: 3720\t Loss: 1.6663\n",
            "Accuracy of the network on the 10000 test images: 71 %\n",
            "Epoch: 3/3\n",
            "\tIteration: 0\t Loss: 0.0473\n",
            "\tIteration: 40\t Loss: 1.6908\n",
            "\tIteration: 80\t Loss: 1.6840\n",
            "\tIteration: 120\t Loss: 1.7100\n",
            "\tIteration: 160\t Loss: 1.6767\n",
            "\tIteration: 200\t Loss: 1.6612\n",
            "\tIteration: 240\t Loss: 1.6659\n",
            "\tIteration: 280\t Loss: 1.6866\n",
            "\tIteration: 320\t Loss: 1.6726\n",
            "\tIteration: 360\t Loss: 1.6689\n",
            "\tIteration: 400\t Loss: 1.7010\n",
            "\tIteration: 440\t Loss: 1.6831\n",
            "\tIteration: 480\t Loss: 1.6782\n",
            "\tIteration: 520\t Loss: 1.6887\n",
            "\tIteration: 560\t Loss: 1.6749\n",
            "\tIteration: 600\t Loss: 1.6717\n",
            "\tIteration: 640\t Loss: 1.7005\n",
            "\tIteration: 680\t Loss: 1.7000\n",
            "\tIteration: 720\t Loss: 1.6802\n",
            "\tIteration: 760\t Loss: 1.6608\n",
            "\tIteration: 800\t Loss: 1.6643\n",
            "\tIteration: 840\t Loss: 1.7002\n",
            "\tIteration: 880\t Loss: 1.6809\n",
            "\tIteration: 920\t Loss: 1.6732\n",
            "\tIteration: 960\t Loss: 1.7038\n",
            "\tIteration: 1000\t Loss: 1.6710\n",
            "\tIteration: 1040\t Loss: 1.6360\n",
            "\tIteration: 1080\t Loss: 1.6743\n",
            "\tIteration: 1120\t Loss: 1.6927\n",
            "\tIteration: 1160\t Loss: 1.6850\n",
            "\tIteration: 1200\t Loss: 1.6826\n",
            "\tIteration: 1240\t Loss: 1.6732\n",
            "\tIteration: 1280\t Loss: 1.6989\n",
            "\tIteration: 1320\t Loss: 1.6787\n",
            "\tIteration: 1360\t Loss: 1.6742\n",
            "\tIteration: 1400\t Loss: 1.6909\n",
            "\tIteration: 1440\t Loss: 1.6644\n",
            "\tIteration: 1480\t Loss: 1.6671\n",
            "\tIteration: 1520\t Loss: 1.6716\n",
            "\tIteration: 1560\t Loss: 1.6912\n",
            "\tIteration: 1600\t Loss: 1.6805\n",
            "\tIteration: 1640\t Loss: 1.6766\n",
            "\tIteration: 1680\t Loss: 1.6456\n",
            "\tIteration: 1720\t Loss: 1.6655\n",
            "\tIteration: 1760\t Loss: 1.6909\n",
            "\tIteration: 1800\t Loss: 1.6444\n",
            "\tIteration: 1840\t Loss: 1.6476\n",
            "\tIteration: 1880\t Loss: 1.6617\n",
            "\tIteration: 1920\t Loss: 1.6653\n",
            "\tIteration: 1960\t Loss: 1.6591\n",
            "\tIteration: 2000\t Loss: 1.6553\n",
            "\tIteration: 2040\t Loss: 1.6544\n",
            "\tIteration: 2080\t Loss: 1.6586\n",
            "\tIteration: 2120\t Loss: 1.6872\n",
            "\tIteration: 2160\t Loss: 1.6645\n",
            "\tIteration: 2200\t Loss: 1.6726\n",
            "\tIteration: 2240\t Loss: 1.6745\n",
            "\tIteration: 2280\t Loss: 1.6805\n",
            "\tIteration: 2320\t Loss: 1.6840\n",
            "\tIteration: 2360\t Loss: 1.6603\n",
            "\tIteration: 2400\t Loss: 1.6617\n",
            "\tIteration: 2440\t Loss: 1.6836\n",
            "\tIteration: 2480\t Loss: 1.6498\n",
            "\tIteration: 2520\t Loss: 1.6887\n",
            "\tIteration: 2560\t Loss: 1.6904\n",
            "\tIteration: 2600\t Loss: 1.6716\n",
            "\tIteration: 2640\t Loss: 1.6567\n",
            "\tIteration: 2680\t Loss: 1.6793\n",
            "\tIteration: 2720\t Loss: 1.6919\n",
            "\tIteration: 2760\t Loss: 1.6749\n",
            "\tIteration: 2800\t Loss: 1.7024\n",
            "\tIteration: 2840\t Loss: 1.6512\n",
            "\tIteration: 2880\t Loss: 1.6569\n",
            "\tIteration: 2920\t Loss: 1.6527\n",
            "\tIteration: 2960\t Loss: 1.6914\n",
            "\tIteration: 3000\t Loss: 1.6683\n",
            "\tIteration: 3040\t Loss: 1.6516\n",
            "\tIteration: 3080\t Loss: 1.6843\n",
            "\tIteration: 3120\t Loss: 1.6732\n",
            "\tIteration: 3160\t Loss: 1.6619\n",
            "\tIteration: 3200\t Loss: 1.6571\n",
            "\tIteration: 3240\t Loss: 1.6713\n",
            "\tIteration: 3280\t Loss: 1.6944\n",
            "\tIteration: 3320\t Loss: 1.6760\n",
            "\tIteration: 3360\t Loss: 1.6504\n",
            "\tIteration: 3400\t Loss: 1.6672\n",
            "\tIteration: 3440\t Loss: 1.6614\n",
            "\tIteration: 3480\t Loss: 1.6731\n",
            "\tIteration: 3520\t Loss: 1.6810\n",
            "\tIteration: 3560\t Loss: 1.6906\n",
            "\tIteration: 3600\t Loss: 1.6644\n",
            "\tIteration: 3640\t Loss: 1.6596\n",
            "\tIteration: 3680\t Loss: 1.6606\n",
            "\tIteration: 3720\t Loss: 1.6720\n",
            "Accuracy of the network on the 10000 test images: 79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wbg1CE6Yk9j",
        "outputId": "9f4f2d7d-8add-4118-a73a-e0e741bab091"
      },
      "source": [
        "#print(predicted)\n",
        "#print(outputs.data)\n",
        "torch.max(outputs.data, 1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([0.9081, 1.0000, 0.9989, 0.6051, 1.0000, 0.9943, 0.9999, 0.8680, 1.0000,\n",
              "        1.0000, 0.9020, 0.9979, 0.9999, 1.0000, 0.9999, 1.0000]), indices=tensor([9, 9, 1, 9, 6, 7, 1, 3, 8, 5, 8, 6, 0, 6, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "6u_00pWDap2B",
        "outputId": "02709f71-b9fe-43a5-e387-b758b7759fc2"
      },
      "source": [
        "# Run this cell with your model to make sure it works and predicts well for the validation data\n",
        "images, labels = next(iter(testloader))\n",
        "images.resize_(images.shape[0], 1, 784)\n",
        "ps = model.forward(images[0,:])\n",
        "view_classify(images[0].view(1, 28, 28), ps)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 349,
              "height": 195
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDK80F-Wap2C"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Exercise 3:</h3>\n",
        "  <p>Write the code for adding <strong style=\"color:#01ff84\">Early Stopping with patience = 2</strong> to the training loop from scratch.</p>\n",
        "  <p><strong style=\"color:#01ff84\">Hint:</strong> Monitor the Validation loss every epoch, and if in 2 epochs, the validation loss does not improve, stop the training loop with <code>break</code>.</p>\n",
        "<div>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDY4cB4hap2D"
      },
      "source": [
        "## TODO: Your training loop here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dPDGtVBap2E"
      },
      "source": [
        "<div style=\"background:#222222; color:#ffffff; padding:20px\">\n",
        "  <h3 style=\"color:#01ff84; margin-top:4px\">Optional:</h3>\n",
        "  <p>Don't you want to use MNIST? Try EMNIST instead! Maybe using the first 10 letters of the alphabet!</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:35:26.981584Z",
          "start_time": "2021-05-26T22:35:26.954522Z"
        },
        "id": "vkSpz363ap2F"
      },
      "source": [
        "# we will need a custom visualization function\n",
        "def view_classify_emnist(img, ps):\n",
        "\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(list(\"abcdefghij\"), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:50:57.571260Z",
          "start_time": "2021-05-26T22:50:57.322172Z"
        },
        "id": "Jrpsb-isap2F"
      },
      "source": [
        "# Define a transform to normalize the data (Preprocessing)\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5)) ])\n",
        "def my_collate(batch):\n",
        "    modified_batch = []\n",
        "    for item in batch:\n",
        "        image, label = item\n",
        "        if label < 10: # only the first ten letters\n",
        "            modified_batch.append(item)\n",
        "    return torch.utils.data._utils.collate.default_collate(modified_batch)\n",
        "\n",
        "\n",
        "# Download and load the training data\n",
        "trainset    = datasets.EMNIST('EMNIST_data/', split=\"letters\", download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, collate_fn=my_collate)\n",
        "\n",
        "# Download and load the test data\n",
        "testset    = datasets.EMNIST('EMNIST_data/', split=\"letters\", download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=True, collate_fn=my_collate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:51:02.493175Z",
          "start_time": "2021-05-26T22:51:02.464301Z"
        },
        "id": "p0ob7AyPap2G"
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:51:03.118421Z",
          "start_time": "2021-05-26T22:51:02.978678Z"
        },
        "id": "684lJRsIap2H",
        "outputId": "b33e3019-60c0-4ddf-e02e-7277efe6cd30"
      },
      "source": [
        "plt.imshow(images[5].numpy().squeeze(), cmap='Greys_r');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 248,
              "width": 251
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-05-26T22:51:06.653639Z",
          "start_time": "2021-05-26T22:51:06.647991Z"
        },
        "id": "QEKYt9xpap2I",
        "outputId": "1fcf2efa-c6ce-47aa-83c9-7ba71f80dbbb"
      },
      "source": [
        "labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 9, 6, 7, 5, 1, 9, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzLa9sz9ap2J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}